{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31138858-ff30-4fbe-8e1f-ec4ee233f78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Q1. What is Random Forest Regressor? \"\"\"\n",
    "\n",
    "# ans\n",
    "\"\"\"  Random Forest Regressor is a machine learning algorithm that belongs to the ensemble learning family. It uses a collection of decision trees to make predictions in regression tasks, where the output is a continuous numerical value. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad7e1b4-c07e-4d86-b27b-d2da6bec4db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Q2. How does Random Forest Regressor reduce the risk of overfitting? \"\"\"\n",
    "\n",
    "# ans\n",
    "\"\"\" Reducing the risk of overfitting: Random Forest Regressor reduces overfitting by training each decision tree on a random subset of the training data and considering only a random subset of features at each split. This introduces diversity among the trees and prevents them from memorizing the noise in the data, leading to a more robust and generalizable model. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3542ec1e-0ffb-4282-a61f-ef9d00c06497",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Q3. How does Random Forest Regressor aggregate the predictions of multiple decision trees? \"\"\"\n",
    "\n",
    "# ans\n",
    "\"\"\" Aggregating predictions: Random Forest Regressor aggregates the predictions of multiple decision trees by averaging their individual predictions. Each tree in the ensemble independently makes a prediction, and the final output is the average of these predictions. This ensemble approach helps in improving the overall predictive accuracy and mitigates the impact of outliers or noise in the data. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23977a09-3456-4c4b-9b40-56f7962bfe98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Q4. What are the hyperparameters of Random Forest Regressor? \"\"\"\n",
    "\n",
    "# ans\n",
    "\"\"\" Number of Trees (n_estimators): The number of decision trees in the ensemble.\n",
    "Maximum Depth of Trees (max_depth): The maximum depth allowed for each decision tree.\n",
    "Minimum Samples Split (min_samples_split): The minimum number of samples required to split an internal node.\n",
    "Minimum Samples Leaf (min_samples_leaf): The minimum number of samples required to be in a leaf node.\n",
    "Maximum Features (max_features): The maximum number of features considered for splitting a node. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08ecbf5-514a-4db1-b34a-12ebf3e2ccf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Q5. What is the difference between Random Forest Regressor and Decision Tree Regressor? \"\"\"\n",
    "\n",
    "# ans\n",
    "\"\"\" Random Forest Regressor is an ensemble of decision trees, whereas Decision Tree Regressor is a single decision tree.\n",
    "Random Forest introduces randomness by training each tree on a random subset of data and features, reducing overfitting.\n",
    "Decision Tree Regressor can be prone to overfitting as it tries to fit the training data precisely. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339b80db-8565-4c48-aac0-8a2cf8749159",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Q6. What are the advantages and disadvantages of Random Forest Regressor? \"\"\"\n",
    "\n",
    "# ans\n",
    "\"\"\" Advantages:\n",
    "\n",
    "High predictive accuracy and generalization.\n",
    "Robust to overfitting due to ensemble nature.\n",
    "Handles a large number of features well.\n",
    "Provides feature importance scores.\n",
    "\n",
    "Disadvantages:\n",
    "\n",
    "Increased computational complexity compared to a single decision tree.\n",
    "Can be challenging to interpret when the ensemble is large.\n",
    "May not perform well on very small datasets. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6a168d-16c2-443c-a936-2ccdb7f20a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Q7. What is the output of Random Forest Regressor?  \"\"\"\n",
    "\n",
    "# ans\n",
    "\"\"\" Output of Random Forest Regressor: The output of a Random Forest Regressor is a continuous numerical value, representing the predicted outcome for the input data. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b4f6d8-3217-4f97-aaca-764b8b09d6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Q8. Can Random Forest Regressor be used for classification tasks?  \"\"\"\n",
    "\n",
    "# ans\n",
    "\"\"\" Random Forest Regressor for classification tasks: While Random Forest Regressor is designed for regression tasks, there is a counterpart called Random Forest Classifier specifically tailored for classification tasks. The main difference is in how the predictions are aggregated, with classification using majority voting instead of averaging. \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
